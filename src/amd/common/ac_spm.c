/*
 * Copyright 2021 Valve Corporation
 *
 * SPDX-License-Identifier: MIT
 */

#include "ac_spm.h"

#include "util/bitscan.h"
#include "util/u_memory.h"
#include "ac_perfcounter.h"

/* SPM counters definition. */
/* GFX10+ */
static struct ac_spm_counter_descr gfx10_num_l2_hits = {TCP, 0, 0x9};
static struct ac_spm_counter_descr gfx10_num_l2_misses = {TCP, 0, 0x12};
static struct ac_spm_counter_descr gfx10_num_scache_hits = {SQ, 0, 0x14f};
static struct ac_spm_counter_descr gfx10_num_scache_misses = {SQ, 0, 0x150};
static struct ac_spm_counter_descr gfx10_num_scache_misses_dup = {SQ, 0, 0x151};
static struct ac_spm_counter_descr gfx10_num_icache_hits = {SQ, 0, 0x12c};
static struct ac_spm_counter_descr gfx10_num_icache_misses = {SQ, 0, 0x12d};
static struct ac_spm_counter_descr gfx10_num_icache_misses_dup = {SQ, 0, 0x12e};
static struct ac_spm_counter_descr gfx10_num_gl1c_hits = {GL1C, 0, 0xe};
static struct ac_spm_counter_descr gfx10_num_gl1c_misses = {GL1C, 0, 0x12};
static struct ac_spm_counter_descr gfx10_num_gl2c_hits = {GL2C, 0, 0x3};
static struct ac_spm_counter_descr gfx10_num_gl2c_misses = {GL2C, 0, 0x23};

static struct ac_spm_counter_create_info gfx10_spm_counters[] = {
   {&gfx10_num_l2_hits},
   {&gfx10_num_l2_misses},
   {&gfx10_num_scache_hits},
   {&gfx10_num_scache_misses},
   {&gfx10_num_scache_misses_dup},
   {&gfx10_num_icache_hits},
   {&gfx10_num_icache_misses},
   {&gfx10_num_icache_misses_dup},
   {&gfx10_num_gl1c_hits},
   {&gfx10_num_gl1c_misses},
   {&gfx10_num_gl2c_hits},
   {&gfx10_num_gl2c_misses},
};

/* GFX10.3+ */
static struct ac_spm_counter_descr gfx103_num_gl2c_misses = {GL2C, 0, 0x2b};

static struct ac_spm_counter_create_info gfx103_spm_counters[] = {
   {&gfx10_num_l2_hits},
   {&gfx10_num_l2_misses},
   {&gfx10_num_scache_hits},
   {&gfx10_num_scache_misses},
   {&gfx10_num_scache_misses_dup},
   {&gfx10_num_icache_hits},
   {&gfx10_num_icache_misses},
   {&gfx10_num_icache_misses_dup},
   {&gfx10_num_gl1c_hits},
   {&gfx10_num_gl1c_misses},
   {&gfx10_num_gl2c_hits},
   {&gfx103_num_gl2c_misses},
};

/* GFX11+ */
static struct ac_spm_counter_descr gfx11_num_l2_misses = {TCP, 0, 0x11};
static struct ac_spm_counter_descr gfx11_num_scache_hits = {SQ_WGP, 0, 0x126};
static struct ac_spm_counter_descr gfx11_num_scache_misses = {SQ_WGP, 0, 0x127};
static struct ac_spm_counter_descr gfx11_num_scache_misses_dup = {SQ_WGP, 0, 0x128};
static struct ac_spm_counter_descr gfx11_num_icache_hits = {SQ_WGP, 0, 0x10e};
static struct ac_spm_counter_descr gfx11_num_icache_misses = {SQ_WGP, 0, 0x10f};
static struct ac_spm_counter_descr gfx11_num_icache_misses_dup = {SQ_WGP, 0, 0x110};

static struct ac_spm_counter_create_info gfx11_spm_counters[] = {
   {&gfx10_num_l2_hits},
   {&gfx11_num_l2_misses},
   {&gfx11_num_scache_hits},
   {&gfx11_num_scache_misses},
   {&gfx11_num_scache_misses_dup},
   {&gfx11_num_icache_hits},
   {&gfx11_num_icache_misses},
   {&gfx11_num_icache_misses_dup},
   {&gfx10_num_gl1c_hits},
   {&gfx10_num_gl1c_misses},
   {&gfx10_num_gl2c_hits},
   {&gfx103_num_gl2c_misses},
};

static struct ac_spm_counter_create_info *
ac_spm_get_counters(const struct radeon_info *info, unsigned *num_counters)
{
   switch (info->gfx_level) {
   case GFX10:
      *num_counters = ARRAY_SIZE(gfx10_spm_counters);
      return gfx10_spm_counters;
   case GFX10_3:
      *num_counters = ARRAY_SIZE(gfx103_spm_counters);
      return gfx103_spm_counters;
   case GFX11:
      *num_counters = ARRAY_SIZE(gfx11_spm_counters);
      return gfx11_spm_counters;
   default:
      unreachable("invalid gfx_level for SPM counters");
   }
}

static struct ac_spm_block_select *
ac_spm_get_block_select(struct ac_spm *spm, const struct ac_pc_block *block)
{
   struct ac_spm_block_select *block_sel, *new_block_sel;
   uint32_t num_block_sel;

   for (uint32_t i = 0; i < spm->num_block_sel; i++) {
      if (spm->block_sel[i].b->b->b->gpu_block == block->b->b->gpu_block)
         return &spm->block_sel[i];
   }

   /* Allocate a new select block if it doesn't already exist. */
   num_block_sel = spm->num_block_sel + 1;
   block_sel = realloc(spm->block_sel, num_block_sel * sizeof(*block_sel));
   if (!block_sel)
      return NULL;

   spm->num_block_sel = num_block_sel;
   spm->block_sel = block_sel;

   /* Initialize the new select block. */
   new_block_sel = &spm->block_sel[spm->num_block_sel - 1];
   memset(new_block_sel, 0, sizeof(*new_block_sel));

   new_block_sel->b = block;
   new_block_sel->num_counters = block->b->b->num_spm_counters;

   /* Broadcast global block writes to SEs and SAs */
   if (!(block->b->b->flags & (AC_PC_BLOCK_SE | AC_PC_BLOCK_SHADER)))
      new_block_sel->grbm_gfx_index = S_030800_SE_BROADCAST_WRITES(1) |
                                      S_030800_SH_BROADCAST_WRITES(1);
   /* Broadcast per SE block writes to SAs */
   else if (block->b->b->flags & AC_PC_BLOCK_SE)
      new_block_sel->grbm_gfx_index = S_030800_SH_BROADCAST_WRITES(1);

   return new_block_sel;
}

struct ac_spm_instance_mapping {
   uint32_t se_index;         /* SE index or 0 if global */
   uint32_t sa_index;         /* SA index or 0 if global or per-SE */
   uint32_t instance_index;
};

static bool
ac_spm_init_instance_mapping(const struct radeon_info *info,
                             const struct ac_pc_block *block,
                             const struct ac_spm_counter_info *counter,
                             struct ac_spm_instance_mapping *mapping)
{
   uint32_t instance_index = 0, se_index = 0, sa_index = 0;

   if (block->b->b->flags & AC_PC_BLOCK_SE) {
      if (block->b->b->gpu_block == SQ) {
         /* Per-SE blocks. */
         se_index = counter->instance / block->num_instances;
         instance_index = counter->instance % block->num_instances;
      } else {
         /* Per-SA blocks. */
         assert(block->b->b->gpu_block == GL1C ||
                block->b->b->gpu_block == TCP);
         se_index = (counter->instance / block->num_instances) / info->max_sa_per_se;
         sa_index = (counter->instance / block->num_instances) % info->max_sa_per_se;
         instance_index = counter->instance % block->num_instances;
      }
   } else {
      /* Global blocks. */
      assert(block->b->b->gpu_block == GL2C);
      instance_index = counter->instance;
   }

   if (se_index >= info->num_se ||
       sa_index >= info->max_sa_per_se ||
       instance_index >= block->num_instances)
      return false;

   mapping->se_index = se_index;
   mapping->sa_index = sa_index;
   mapping->instance_index = instance_index;

   return true;
}

static void
ac_spm_init_muxsel(const struct ac_pc_block *block,
                   const struct ac_spm_instance_mapping *mapping,
                   struct ac_spm_counter_info *counter,
                   uint32_t spm_wire)
{
   struct ac_spm_muxsel *muxsel = &counter->muxsel;

   muxsel->counter = 2 * spm_wire + (counter->is_even ? 0 : 1);
   muxsel->block = block->b->b->spm_block_select;
   muxsel->shader_array = mapping->sa_index;
   muxsel->instance = mapping->instance_index;
}

static bool
ac_spm_map_counter(struct ac_spm *spm, struct ac_spm_block_select *block_sel,
                   struct ac_spm_counter_info *counter,
                   uint32_t *spm_wire)
{
   if (block_sel->b->b->b->gpu_block == SQ) {
      for (unsigned i = 0; i < ARRAY_SIZE(spm->sq_block_sel); i++) {
         struct ac_spm_block_select *sq_block_sel = &spm->sq_block_sel[i];
         struct ac_spm_counter_select *cntr_sel = &sq_block_sel->counters[0];
         if (i < spm->num_used_sq_block_sel)
            continue;

         /* SQ doesn't support 16-bit counters. */
         cntr_sel->sel0 |= S_036700_PERF_SEL(counter->event_id) |
                           S_036700_SPM_MODE(3) | /* 32-bit clamp */
                           S_036700_PERF_MODE(0);
         cntr_sel->active |= 0x3;

         /* 32-bits counter are always even. */
         counter->is_even = true;

         /* One wire per SQ module. */
         *spm_wire = i;

         spm->num_used_sq_block_sel++;
         return true;
      }
   } else {
      /* Generic blocks. */
      for (unsigned i = 0; i < block_sel->num_counters; i++) {
         struct ac_spm_counter_select *cntr_sel = &block_sel->counters[i];
         int index = ffs(~cntr_sel->active) - 1;

         switch (index) {
         case 0: /* use S_037004_PERF_SEL */
            cntr_sel->sel0 |= S_037004_PERF_SEL(counter->event_id) |
                              S_037004_CNTR_MODE(1) | /* 16-bit clamp */
                              S_037004_PERF_MODE(0); /* accum */
            break;
         case 1: /* use S_037004_PERF_SEL1 */
            cntr_sel->sel0 |= S_037004_PERF_SEL1(counter->event_id) |
                              S_037004_PERF_MODE1(0);
            break;
         case 2: /* use S_037004_PERF_SEL2 */
            cntr_sel->sel1 |= S_037008_PERF_SEL2(counter->event_id) |
                              S_037008_PERF_MODE2(0);
            break;
         case 3: /* use S_037004_PERF_SEL3 */
            cntr_sel->sel1 |= S_037008_PERF_SEL3(counter->event_id) |
                              S_037008_PERF_MODE3(0);
            break;
         default:
            return false;
         }

         /* Mark this 16-bit counter as used. */
         cntr_sel->active |= 1 << index;

         /* Determine if the counter is even or odd. */
         counter->is_even = !(index % 2);

         /* Determine the SPM wire (one wire holds two 16-bit counters). */
         *spm_wire = !!(index >= 2);

         return true;
      }
   }

   return false;
}

static bool
ac_spm_add_counter(const struct radeon_info *info,
                   const struct ac_perfcounters *pc,
                   struct ac_spm *spm,
                   const struct ac_spm_counter_create_info *counter_info)
{
   struct ac_spm_instance_mapping instance_mapping = {0};
   struct ac_spm_counter_info *counter;
   struct ac_spm_block_select *block_sel;
   struct ac_pc_block *block;
   uint32_t spm_wire;

   /* Check if the GPU block is valid. */
   block = ac_pc_get_block(pc, counter_info->b->gpu_block);
   if (!block) {
      fprintf(stderr, "ac/spm: Invalid GPU block.\n");
      return false;
   }

   /* Check if the number of instances is valid. */
   if (counter_info->b->instance > block->num_global_instances - 1) {
      fprintf(stderr, "ac/spm: Invalid instance ID.\n");
      return false;
   }

   /* Check if the event ID is valid. */
   if (counter_info->b->event_id > block->b->selectors) {
      fprintf(stderr, "ac/spm: Invalid event ID.\n");
      return false;
   }

   counter = &spm->counters[spm->num_counters];
   spm->num_counters++;

   counter->gpu_block = counter_info->b->gpu_block;
   counter->instance = counter_info->b->instance;
   counter->event_id = counter_info->b->event_id;

   /* Get the select block used to configure the counter. */
   block_sel = ac_spm_get_block_select(spm, block);
   if (!block_sel)
      return false;

   /* Initialize instance mapping for the counter. */
   if (!ac_spm_init_instance_mapping(info, block, counter, &instance_mapping)) {
      fprintf(stderr, "ac/spm: Failed to initialize instance mapping.\n");
      return false;
   }

   /* Map the counter to the select block. */
   if (!ac_spm_map_counter(spm, block_sel, counter, &spm_wire)) {
      fprintf(stderr, "ac/spm: No free slots available!\n");
      return false;
   }

   /* Determine the counter segment type. */
   if (block->b->b->flags & AC_PC_BLOCK_SE) {
      counter->segment_type = instance_mapping.se_index;
   } else {
      counter->segment_type = AC_SPM_SEGMENT_TYPE_GLOBAL;
   }

   /* Configure the muxsel for SPM. */
   ac_spm_init_muxsel(block, &instance_mapping, counter, spm_wire);

   return true;
}

static void
ac_spm_fill_muxsel_ram(struct ac_spm *spm,
                       enum ac_spm_segment_type segment_type,
                       uint32_t offset)
{
   struct ac_spm_muxsel_line *mappings = spm->muxsel_lines[segment_type];
   uint32_t even_counter_idx = 0, even_line_idx = 0;
   uint32_t odd_counter_idx = 0, odd_line_idx = 1;

   /* Add the global timestamps first. */
   if (segment_type == AC_SPM_SEGMENT_TYPE_GLOBAL) {
      struct ac_spm_muxsel global_timestamp_muxsel = {
         .counter = 0x30,
         .block = 0x3,
         .shader_array = 0,
         .instance = 0x1e,
      };

      for (unsigned i = 0; i < 4; i++) {
         mappings[even_line_idx].muxsel[even_counter_idx++] = global_timestamp_muxsel;
      }
   }

   for (unsigned i = 0; i < spm->num_counters; i++) {
      struct ac_spm_counter_info *counter = &spm->counters[i];

      if (counter->segment_type != segment_type)
         continue;

      if (counter->is_even) {
         counter->offset =
            (offset + even_line_idx) * AC_SPM_NUM_COUNTER_PER_MUXSEL + even_counter_idx;

         mappings[even_line_idx].muxsel[even_counter_idx] = spm->counters[i].muxsel;
         if (++even_counter_idx == AC_SPM_NUM_COUNTER_PER_MUXSEL) {
            even_counter_idx = 0;
            even_line_idx += 2;
         }
      } else {
         counter->offset =
            (offset + odd_line_idx) * AC_SPM_NUM_COUNTER_PER_MUXSEL + odd_counter_idx;

         mappings[odd_line_idx].muxsel[odd_counter_idx] = spm->counters[i].muxsel;
         if (++odd_counter_idx == AC_SPM_NUM_COUNTER_PER_MUXSEL) {
            odd_counter_idx = 0;
            odd_line_idx += 2;
         }
      }
   }
}

bool ac_init_spm(const struct radeon_info *info,
                 const struct ac_perfcounters *pc,
                 struct ac_spm *spm)
{
   unsigned num_counters;
   const struct ac_spm_counter_create_info *counters = ac_spm_get_counters(info, &num_counters);
   uint32_t offset = 0;

   spm->counters = CALLOC(num_counters, sizeof(*spm->counters));
   if (!spm->counters)
      return false;

   for (unsigned i = 0; i < num_counters; i++) {
      if (!ac_spm_add_counter(info, pc, spm, &counters[i])) {
         fprintf(stderr, "ac/spm: Failed to add SPM counter (%d).\n", i);
         return false;
      }
   }

   /* Determine the segment size and create a muxsel ram for every segment. */
   for (unsigned s = 0; s < AC_SPM_SEGMENT_TYPE_COUNT; s++) {
      unsigned num_even_counters = 0, num_odd_counters = 0;

      if (s == AC_SPM_SEGMENT_TYPE_GLOBAL) {
         /* The global segment always start with a 64-bit timestamp. */
         num_even_counters += AC_SPM_GLOBAL_TIMESTAMP_COUNTERS;
      }

      /* Count the number of even/odd counters for this segment. */
      for (unsigned c = 0; c < spm->num_counters; c++) {
         struct ac_spm_counter_info *counter = &spm->counters[c];

         if (counter->segment_type != s)
            continue;

         if (counter->is_even) {
            num_even_counters++;
         } else {
            num_odd_counters++;
         }
      }

      /* Compute the number of lines. */
      unsigned even_lines =
         DIV_ROUND_UP(num_even_counters, AC_SPM_NUM_COUNTER_PER_MUXSEL);
      unsigned odd_lines =
         DIV_ROUND_UP(num_odd_counters, AC_SPM_NUM_COUNTER_PER_MUXSEL);
      unsigned num_lines = (even_lines > odd_lines) ? (2 * even_lines - 1) : (2 * odd_lines);

      spm->muxsel_lines[s] = CALLOC(num_lines, sizeof(*spm->muxsel_lines[s]));
      if (!spm->muxsel_lines[s])
         return false;
      spm->num_muxsel_lines[s] = num_lines;
   }

   /* RLC uses the following order: Global, SE0, SE1, SE2, SE3. */
   ac_spm_fill_muxsel_ram(spm, AC_SPM_SEGMENT_TYPE_GLOBAL, 0);
   offset += spm->num_muxsel_lines[AC_SPM_SEGMENT_TYPE_GLOBAL];

   for (unsigned i = 0; i < info->num_se; i++) {
      assert(i < AC_SPM_SEGMENT_TYPE_GLOBAL);
      ac_spm_fill_muxsel_ram(spm, i, offset);
      offset += spm->num_muxsel_lines[i];
   }

   return true;
}

void ac_destroy_spm(struct ac_spm *spm)
{
   for (unsigned s = 0; s < AC_SPM_SEGMENT_TYPE_COUNT; s++) {
      FREE(spm->muxsel_lines[s]);
   }
   FREE(spm->block_sel);
   FREE(spm->counters);
}

static uint32_t ac_spm_get_sample_size(const struct ac_spm *spm)
{
   uint32_t sample_size = 0; /* in bytes */

   for (unsigned s = 0; s < AC_SPM_SEGMENT_TYPE_COUNT; s++) {
      sample_size += spm->num_muxsel_lines[s] * AC_SPM_MUXSEL_LINE_SIZE * 4;
   }

   return sample_size;
}

static uint32_t ac_spm_get_num_samples(const struct ac_spm *spm)
{
   uint32_t sample_size = ac_spm_get_sample_size(spm);
   uint32_t *ptr = (uint32_t *)spm->ptr;
   uint32_t data_size, num_lines_written;
   uint32_t num_samples = 0;

   /* Get the data size (in bytes) written by the hw to the ring buffer. */
   data_size = ptr[0];

   /* Compute the number of 256 bits (16 * 16-bits counters) lines written. */
   num_lines_written = data_size / (2 * AC_SPM_NUM_COUNTER_PER_MUXSEL);

   /* Check for overflow. */
   if (num_lines_written % (sample_size / 32)) {
      abort();
   } else {
      num_samples = num_lines_written / (sample_size / 32);
   }

   return num_samples;
}

void ac_spm_get_trace(const struct ac_spm *spm, struct ac_spm_trace *trace)
{
   memset(trace, 0, sizeof(*trace));

   trace->ptr = spm->ptr;
   trace->sample_interval = spm->sample_interval;
   trace->num_counters = spm->num_counters;
   trace->counters = spm->counters;
   trace->sample_size_in_bytes = ac_spm_get_sample_size(spm);
   trace->num_samples = ac_spm_get_num_samples(spm);
}
